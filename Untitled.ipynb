{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T08:19:02.398984Z",
     "start_time": "2019-04-24T08:18:59.851874Z"
    },
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get 100 IPs from 31f.\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import time\n",
    "import requests\n",
    "from lxml import etree\n",
    "\n",
    "from utils.logger import logger\n",
    "\n",
    "class Parser(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def parse_kuaidaili(self, num=5):\n",
    "        items = []\n",
    "        target = ['inha', 'intr']\n",
    "        for target_id in range(len(target)):\n",
    "            for page_id in range(1, num+1):\n",
    "                response = requests.get(\"https://www.kuaidaili.com/free/%s/%d/\" % (target[target_id], page_id))\n",
    "                if response.status_code != 200:\n",
    "                    logger.error(\"download kuaidaili page <%s,%d> failed.(status_code:%d)\" % (\n",
    "                        target[target_id], page_id, response.status_code))\n",
    "                    break\n",
    "                html = etree.HTML(response.text)\n",
    "                trs = html.xpath('//*[@id=\"list\"]/table/tbody/tr')\n",
    "                for tr in trs:\n",
    "                    item = {}\n",
    "                    tds = tr.xpath('td')\n",
    "                    item['ip'] = tds[0].text.strip()                # IP\n",
    "                    item['port'] = tds[1].text.strip()              # Port\n",
    "                    item['http_type'] = tds[3].text.strip()         # HTTP or HTTPS\n",
    "                    items.append(item)\n",
    "                time.sleep(1)\n",
    "        logger.info(\"get %d IPs from kuaidaili.\" % len(items))\n",
    "        return items\n",
    "\n",
    "    def parse_shenjidaili(self):\n",
    "        items = []\n",
    "        response = requests.get(\"http://www.shenjidaili.com/open/\")\n",
    "        if response.status_code == 200:\n",
    "            html = etree.HTML(response.text)\n",
    "            trs_http = html.xpath('//*[@id=\"pills-stable_http\"]/table/tr')[1:]\n",
    "            trs_https = html.xpath('//*[@id=\"pills-stable_https\"]/table/tr')[1:]\n",
    "            trs = trs_http + trs_https\n",
    "            for tr in trs:\n",
    "                item = {}\n",
    "                tds = tr.xpath('td')\n",
    "                item['ip'] = tds[0].text.strip()                # IP\n",
    "                item['port'] = tds[1].text.strip()              # Port\n",
    "                item['http_type'] = tds[3].text.strip()         # HTTP or HTTPS\n",
    "                items.append(item)\n",
    "        else:\n",
    "            logger.error(\"download shenjidaili page failed.(status_code:%d)\")\n",
    "        logger.info(\"get %d IPs from shenjidaili.\" % len(items))\n",
    "        return items\n",
    "\n",
    "    def parse_qydaili(self, num = 10):\n",
    "        items = []\n",
    "        for page_id in range(1, num+1):\n",
    "            response = requests.get(\"http://www.qydaili.com/free/?action=china&page=%d\" % page_id)\n",
    "            if response.status_code != 200:\n",
    "                logger.error(\"download qydaili page <%d> failed.(status_code:%d)\" % (page_id,response.status_code))\n",
    "                break\n",
    "            html = etree.HTML(response.text)\n",
    "            trs = html.xpath('//table/tbody/tr')\n",
    "            for tr in trs:\n",
    "                item = {}\n",
    "                tds = tr.xpath('td')\n",
    "                item['ip'] = tds[0].text.strip()                # IP\n",
    "                item['port'] = tds[1].text.strip()              # Port\n",
    "                item['http_type'] = tds[3].text.strip()         # HTTP or HTTPS\n",
    "                items.append(item)\n",
    "            time.sleep(1)\n",
    "        logger.info(\"get %d IPs from qydaili.\" % len(items))\n",
    "        return items\n",
    "\n",
    "    def parse_superfastip(self, num = 10):\n",
    "        items = []\n",
    "        for page_id in range(1, num+1):\n",
    "            response = requests.get(\"http://www.superfastip.com/welcome/freeip/%d\" % page_id)\n",
    "            if response.status_code != 200:\n",
    "                logger.error(\"download superfastip page <%d> failed.(status_code:%d)\" % (page_id,response.status_code))\n",
    "                break\n",
    "            html = etree.HTML(response.text)\n",
    "            trs = html.xpath('//table/tbody/tr')\n",
    "            for tr in trs:\n",
    "                item = {}\n",
    "                tds = tr.xpath('td')\n",
    "                item['ip'] = tds[0].text.strip()                # IP\n",
    "                item['port'] = tds[1].text.strip()              # Port\n",
    "                item['http_type'] = tds[3].text.strip()         # HTTP or HTTPS\n",
    "                items.append(item)\n",
    "            time.sleep(1)\n",
    "        logger.info(\"get %d IPs from superfastip.\" % len(items))\n",
    "        return items\n",
    "\n",
    "    def parse_89ip(self, num=18):\n",
    "        items = []\n",
    "        for page_id in range(1, num+1):\n",
    "            response = requests.get(\"http://www.89ip.cn/index_%d.html\" % page_id)\n",
    "            if response.status_code != 200:\n",
    "                logger.error(\"download 89ip page <%d> failed.(status_code:%d)\" % (page_id,response.status_code))\n",
    "                break\n",
    "            html = etree.HTML(response.text)\n",
    "            trs = html.xpath('//table/tbody/tr')\n",
    "            for tr in trs:\n",
    "                item = {}\n",
    "                tds = tr.xpath('td')\n",
    "                item['ip'] = tds[0].text.strip()        # IP\n",
    "                item['port'] = tds[1].text.strip()      # Port\n",
    "                item['http_type'] = ''                  # HTTP or HTTPS\n",
    "                items.append(item)\n",
    "            time.sleep(1)\n",
    "        logger.info(\"get %d IPs from 89ip.\" % len(items))\n",
    "        return items\n",
    "\n",
    "    def parse_data5u(self):\n",
    "        target = ['', '/gngn','/gnpt','/gwgn','/gwpt']\n",
    "        header = {\n",
    "            'Host': 'www.data5u.com',\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:63.0) Gecko/20100101 Firefox/63.0',\n",
    "            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\n",
    "            'Accept-Language': 'zh-CN,zh;q=0.8,zh-TW;q=0.7,zh-HK;q=0.5,en-US;q=0.3,en;q=0.2',\n",
    "            'Connection': 'keep-alive',\n",
    "            'Upgrade-Insecure-Requests': '1'\n",
    "        }\n",
    "        base_url = \"http://www.data5u.com/free%s/index.shtml\"\n",
    "        items = []\n",
    "        for page_id in range(len(target)):\n",
    "            response = requests.get(base_url % target[page_id], headers = header)\n",
    "            # print(response.text)\n",
    "            if response.status_code != 200:\n",
    "                logger.error(\"download data5u page <%s> failed.(status_code:%d)\" % (target[page_id],response.status_code))\n",
    "                break\n",
    "            html = etree.HTML(response.text)\n",
    "            trs = html.xpath('//ul[@class=\"l2\"]')\n",
    "            for tr in trs:\n",
    "                item = {}\n",
    "                tds = tr.xpath('span/li')\n",
    "                item['ip'] = tds[0].text.strip()                # IP\n",
    "                item['port'] = tds[1].text.strip()              # Port\n",
    "                item['http_type'] = tds[3].text.strip()         # HTTP or HTTPS\n",
    "                items.append(item)\n",
    "            time.sleep(1)\n",
    "        logger.info(\"get %d IPs from data5u.\" % len(items))\n",
    "        return items\n",
    "\n",
    "    ''' 521 问题需要绕过 js \n",
    "    def parse_66ip(self, num=5):\n",
    "        items = []\n",
    "        for page_id in range(1, num+1):\n",
    "            response = requests.get(\"http://www.66ip.cn/%d.html\" % page_id)\n",
    "            if response.status_code != 200:\n",
    "                logger.error(\"download 66ip page <%d> failed.(status_code:%d)\" % (page_id, response.status_code))\n",
    "                break\n",
    "            html = etree.HTML(response.text)\n",
    "            trs = html.xpath('//table/tr')\n",
    "            for tr in trs:\n",
    "                item = {}\n",
    "                tds = tr.xpath('td')\n",
    "                item['ip'] = tds[0].text.strip()        # IP\n",
    "                item['port'] = tds[1].text.strip()      # Port\n",
    "                item['http_type'] = ''                  # HTTP or HTTPS\n",
    "                items.append(item)\n",
    "            time.sleep(1)\n",
    "        logger.info(\"get %d IPs from 66ip.\" % len(items))\n",
    "        return items\n",
    "    '''\n",
    "\n",
    "    def parse_31f(self):\n",
    "        target = ['http-proxy/', 'https-proxy/']\n",
    "        base_url = \"http://31f.cn/%s\"\n",
    "        items = []\n",
    "        for page_id in range(len(target)):\n",
    "            response = requests.get(base_url % target[page_id])\n",
    "            if response.status_code != 200:\n",
    "                logger.error(\"download 66ip page <%s> failed.\" % (target[page_id],response.status_code))\n",
    "                break\n",
    "            html = etree.HTML(response.text)\n",
    "            trs = html.xpath('//table[1]/tr')\n",
    "            for tr in trs[1:]:\n",
    "                item = {}\n",
    "                tds = tr.xpath('td')\n",
    "                item['ip'] = tds[1].text.strip()                # IP\n",
    "                item['port'] = tds[2].text.strip()              # Port\n",
    "                item['http_type'] = 'http' if page_id == 0 else 'https' # HTTP or HTTPS\n",
    "                items.append(item)\n",
    "            time.sleep(1)\n",
    "        logger.info(\"get %d IPs from 31f.\" % len(items))\n",
    "        return items\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = Parser()\n",
    "\n",
    "    res = parser.parse_31f()\n",
    "    print(len(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-17T14:15:19.020266Z",
     "start_time": "2019-04-17T14:15:17.320904Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "var _58=function(){setTimeout('location.href=location.pathname+location.search.replace(/[\\?|&]captcha-challenge/,\\'\\')',1500);document.cookie='__jsl_clearance=1555510517.408|0|'+(function(){var _58=[(-~(+!!/!/)+[]+[[]][0]),[-~[]]+[5],[-~[]]+(~~![]+[[]][0]),[-~[]]+[-~(+[])-~[]+4],[5],[-~[]]+[-~[]],[-~[]]+[-~[]+(-~![]+[-~((-~{}+[-~{}-~{}]>>-~{}-~{}))]>>-~![])],[-~[]+(-~![]+[-~((-~{}+[-~{}-~{}]>>-~{}-~{}))]>>-~![])],[-~((-~{}<<((+!!/!/)|-~(+!!/!/))))],[-~[]]+(-~(+!!/!/)+[]+[[]][0]),[-~[]]+(-~[(-~{}+[-~{}-~{}]>>-~{}-~{})+(-~{}+[-~{}-~{}]>>-~{}-~{})]+[]+[[]][0]),[-~[-~{}-~{}]],[-~[]],[(-~{}<<2)],[-~[]]+[-~[-~{}-~{}]],[-~[]]+[(-~{}<<2)],[-~(+[])-~[]+4],(-~[(-~{}+[-~{}-~{}]>>-~{}-~{})+(-~{}+[-~{}-~{}]>>-~{}-~{})]+[]+[[]][0]),(~~![]+[[]][0])];for(var _9=0;_9<_58.length;_9++){_58[_9]=['D','mv','C',(-~[(-~{}+[-~{}-~{}]>>-~{}-~{})+(-~{}+[-~{}-~{}]>>-~{}-~{})]+[]+[[]][0])+[[(-~[]<<-~[])]/~~{}+[]+[[]][0]][0].charAt(-~[-~{}-~{}]+(-~[]<<-~[])+(-~[]<<-~[]))+[{}+[]][0].charAt((-~{}<<((+!!/!/)|-~(+!!/!/)))),(-~(+!!/!/)+[]+[[]][0]),'U','Bk%',[-~[-~{}-~{}]],[!-{}+[]+[[]][0]][0].charAt(~~![])+(((-~{}+[-~{}-~{}]>>-~{}-~{}))/~~''+[[]][0]).charAt(-~{}-~{}),'X','GYq',(~~![]+[[]][0])+[-~[-~{}-~{}]]+(window['_p'+'hantom']+[]).charAt(3),[-~(+[])-~[]+4]+(!!window.headless+[[]][0]).charAt(2),'%',(-~(+!!/!/)+[]+[[]][0]),[-~[]]+(+[-~(+[]), ~~![]]+[]+[]).charAt(-~(+[])),[-~[]+(-~![]+[-~((-~{}+[-~{}-~{}]>>-~{}-~{}))]>>-~![])]+[-~[-~{}-~{}]],'k','K'][_58[_9]]};return _58.join('')})()+';Expires=Wed, 17-Apr-19 15:15:17 GMT;Path=/;'};if((function(){try{return !!window.addEventListener;}catch(e){return false;}})()){document.addEventListener('DOMContentLoaded',_58,false)}else{document.attachEvent('onreadystatechange',_58)}\n"
     ]
    }
   ],
   "source": [
    "import execjs\n",
    "import re\n",
    "response = requests.get(\"http://www.66ip.cn/1.html\")\n",
    "if response.status_code == 521:\n",
    "#res = response.text.replace(\"<script>\",\"\").replace(\"eval\",\"\").replace(\"</script>.*\",\"\").strip('\\\\n')\n",
    "    res = ''.join(re.findall('<script>(.*?)</script>', response.text))\n",
    "    res = res.replace('eval','var eval_test=')\n",
    "    x=execjs.compile(res)\n",
    "    print(x.eval('eval_test'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T08:19:16.096909Z",
     "start_time": "2019-04-24T08:19:15.303310Z"
    },
    "code_folding": [
     7
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import time\n",
    "import requests\n",
    "from lxml import etree\n",
    "\n",
    "from utils.logger import logger\n",
    "\n",
    "HTTP_TYPE = {\n",
    "    'HTTP':1,\n",
    "    'HTTPS':2,\n",
    "    'HTTP,HTTPS':3\n",
    "}\n",
    "\n",
    "class Checker(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def _check_ip(self, ip):\n",
    "        ip_regex='^((25[0-5]|2[0-4]\\d|1\\d{2}|[1-9]?\\d)\\.){3}(25[0-5]|2[0-4]\\d|1\\d{2}|[1-9]?\\d)$'\n",
    "        return re.match(ip_regex, ip) is not None\n",
    "        \n",
    "    def _check_port(self, port):\n",
    "        flag = True\n",
    "        try:\n",
    "            temp = int(port)\n",
    "            if temp < 0 or temp > 65535:\n",
    "                flag = False\n",
    "        except ValueError:\n",
    "            logger.error(\"%s is not a valid port.\" % srt(port) )\n",
    "            flag = False\n",
    "        return flag\n",
    "    \n",
    "    def check(self, ip, port, timeout=5):\n",
    "        http_type = 0\n",
    "        if self._check_ip(ip) and self._check_port(port):\n",
    "            try:\n",
    "                proxies = {\"http\" : \"http://%s:%d\" % (ip, port)}\n",
    "                res = requests.get('http://www.httpbin.org/headers', proxies=proxies, timeout=timeout)\n",
    "                if res.ok:\n",
    "                    http_type |= 1\n",
    "            except:\n",
    "                logger.error(\"<http://%s:%d> is not available.\" % (ip,port))\n",
    "            try:\n",
    "                proxies = {\"https\" : \"https://%s:%d\" % (ip, port)}\n",
    "                requests.get('http://www.httpbin.org/headers', proxies=proxies, timeout=timeout)\n",
    "                if res.ok:\n",
    "                    http_type |= 2\n",
    "            except:\n",
    "                logger.error(\"<https://%s:%d> is not available.\" % (ip,port))\n",
    "        \n",
    "        if http_type > 0:\n",
    "            return (ip, port, http_type)\n",
    "        return None\n",
    "\n",
    "    def get_address():\n",
    "        pass\n",
    "if __name__ == '__main__':\n",
    "    checker = Checker()\n",
    "    print(checker.check('118.24.61.165', 8118))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ProxyHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "from parser import Parser\n",
    "from checker import Checker\n",
    "\n",
    "class ProxyHub(object):\n",
    "    def __init__(self):\n",
    "        self.pre_working_list = []\n",
    "        self.working_list = []\n",
    "        self.error_list = []\n",
    "    \n",
    "    def _parser_threading(self):\n",
    "        parser = Parser()\n",
    "        while True:\n",
    "            self.pre_working_list.extend(parser.parse_kuaidaili())\n",
    "            self.pre_working_list.extend(parser.parse_qydaili())\n",
    "            self.pre_working_list.extend(parser.parse_data5u())\n",
    "            self.pre_working_list.extend(parser.parse_shenjidaili())\n",
    "            self.pre_working_list.extend(parser.parse_superfastip())\n",
    "            self.pre_working_list.extend(parser.parse_31f())\n",
    "            self.pre_working_list.extend(parser.parse_89ip())\n",
    "            print(len(self.pre_working_list), len(self.working_list))\n",
    "            sleep(30)\n",
    "    \n",
    "    def _checker_thread_1(self):\n",
    "        checker = Checker()\n",
    "        while True:\n",
    "            if len(self.pre_working_list) > 0:\n",
    "                if len(self.pre_working_list) > 50:\n",
    "                    sleep(1)\n",
    "                item = pre_working_list.pop(0)\n",
    "                res = checker.check(item['ip'],item['port'])\n",
    "                if res:\n",
    "                    self.working_list.append(res)\n",
    "            else:\n",
    "                sleep(1)\n",
    "    \n",
    "    def start(self):\n",
    "        pass\n",
    "        \n",
    "    def get(self, n=1, callback = None):\n",
    "        callback()\n",
    "        \n",
    "    def stop(self):\n",
    "        pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "notify_time": "10"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
